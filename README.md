# Ship Detection Pipeline

A comprehensive pipeline for ship detection from Sentinel satellite imagery using deep learning.

## Architecture

The project is divided into four main components:

### CPU Operations (`/cpu`)
- GDAL-based operations for image processing
- Handles projections and TiTiler integration
- Deployable on Cloud Run

### GPU Operations (`/gpu`)
- Deep learning training and inference using TorchGeo
- Modal.com deployment for GPU access
- Local GPU support for development

### Web Interface (`/web`)
- Image selection interface
- Annotation tools
- Results visualization
- Built with [your preferred frontend framework]

### API (`/api`)
- Orchestrates CPU and GPU operations
- Handles Supabase database interactions
- RESTful endpoints for web interface

## Technologies

- **TorchGeo**: Deep learning framework for geospatial data
- **GDAL**: Geospatial data processing
- **Supabase**: Backend database
- **Modal**: GPU cloud computing
- **Cloud Run**: CPU operations deployment

## Setup

1. Clone the repository:

```bash
git clone [repository-url]
cd ship-detection-pipeline
```

2. Create and activate a virtual environment:

```bash
pyenv install 3.10.16
pyenv virtualenv 3.10.16 pipeline
pyenv local pipeline
```

3. Install dependencies:

```bash
make setup
```

4. Copy `.env.template` to `.env` and fill in your credentials:

```bash
cp .env.template .env
```

Edit .env with your credentials:

CDSE_USERNAME: Your Copernicus Data Space username
CDSE_PASSWORD: Your Copernicus Data Space password
Here is where you can get your credentials:

CDSE credentials from https://dataspace.copernicus.eu/
(Optional) Sentinel Hub credentials from https://api.sentinel-hub.com/oauth/token/

5. Setup Supabase:

Create table:

```sql
CREATE TABLE public.sentinel_images (
  id bigint GENERATED BY DEFAULT AS IDENTITY NOT NULL,
  created_at timestamp with time zone NOT NULL DEFAULT now(),
  title text NULL,
  timestamp text NULL,
  metadata text NULL,
  identifier text NOT NULL,
  CONSTRAINT sentinel_images_pkey PRIMARY KEY (id, identifier),
  CONSTRAINT sentinel_images_ident_key UNIQUE (identifier)
);
```

Create PostGIS extension and add footprint column:

```sql
CREATE SCHEMA IF NOT EXISTS extensions;
CREATE EXTENSION IF NOT EXISTS postgis SCHEMA extensions;
ALTER TABLE public.sentinel_images ADD COLUMN footprint GEOMETRY;
```


## Development

- Run tests: `make test`
- Run linting: `make lint`
- Build Docker image: `make docker-build`
- Run Docker container: `make docker-run`

## Project Structure


⌘K to generate a command
We will create a pipeline for ship detection from Sentinel images

Here is the structure that I need :
cpu : mostly GDAL functions running locally or deployed on CloudRun. Deals with projections and TiTiler
gpu: since CloudRun has no GPU, we will use modal for deep learning training (should also work locally if host has a GPU) + inference tool
web : web interface for selecting the Sentinel image and displaying it + annotation tool and display tool.
the backend database will be supabase.
api : a wrapper around cpu, gpu cloud function and also supabase calls

We will probably need to use @https://torchgeo.readthedocs.io/en/stable/
Check if @https://rastervision.io/  could be beneficial

Can you create the folders, README, Makefile and Dockerfile ?


I'll help you create the initial project structure based on your requirements. I'll create the necessary files and explain their purpose.
First, let's create the folder structure and main files:
delete
\
bash
git clone [repository-url]
cd ship-detection

2. Create and activate a virtual environment:
bash
python -m venv venv
source venv/bin/activate # Linux/Mac
or
.\venv\Scripts\activate # Windows
3. Install dependencies:
bash
make setup
4. Copy `.env.template` to `.env` and fill in your credentials:
bash
cp .env.template .env

## Development

- Run tests: `make test`
- Run linting: `make lint`
- Build Docker image: `make docker-build`
- Run Docker container: `make docker-run`

## Project Structure
.
├── api/ # API wrapper
├── cpu/ # GDAL and projection operations
├── gpu/ # Deep learning training and inference
├── web/ # Web interface
├── tests/ # Test suite
├── .env.template # Environment variables template
├── .gitignore # Git ignore rules
├── Dockerfile # Docker configuration
├── Makefile # Development commands
└── README.md # This file


## Contributing

[Add contribution guidelines]

## License

[Add license information]
